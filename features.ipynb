{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('data/raw/2023*-capitalbikeshare-tripdata.csv')\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Should we collect some basic stats about what gets thrown out here?\n",
    "df = df[\n",
    "    df['start_station_name'].notna() &\n",
    "    (df['start_station_name'].str.strip() != '') &\n",
    "    df['end_station_name'].notna() &\n",
    "    (df['end_station_name'].str.strip() != '')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"data/raw/Capital_Bikeshare_Locations.csv\")\n",
    "# Match trips and stations so that only trips starting and ending in **still active stations** are kept\n",
    "# FIXME: Should we collect some basic stats about what gets thrown out here?\n",
    "matched_df = df[df['start_station_name'].isin(station_data['NAME']) &\n",
    "                df['end_station_name'].isin(station_data['NAME'])].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert start/end times into start/end hours \n",
    "matched_df['started_at'] = pd.to_datetime(matched_df['started_at'])\n",
    "matched_df['ended_at'] = pd.to_datetime(matched_df['ended_at'])\n",
    "\n",
    "matched_df['start_hour'] = matched_df['started_at'].dt.floor('h')\n",
    "matched_df['end_hour'] = matched_df['ended_at'].dt.floor('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of arrivals/departures from/to station per respective hour\n",
    "departures = matched_df.groupby(['start_station_name', 'start_hour']).size().reset_index(name='departures')\n",
    "departures.rename(columns={'start_station_name': 'station_name', 'start_hour': 'hour'}, inplace=True)\n",
    "\n",
    "arrivals = matched_df.groupby(['end_station_name', 'end_hour']).size().reset_index(name='arrivals')\n",
    "arrivals.rename(columns={'end_station_name': 'station_name', 'end_hour': 'hour'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_hourly = pd.merge(departures, arrivals, on=['station_name', 'hour'], how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_time_index = pd.date_range(start=station_hourly['hour'].min(), end=station_hourly['hour'].max(), freq='h')\n",
    "stations = station_hourly['station_name'].unique()\n",
    "full_index = pd.MultiIndex.from_product([stations, full_time_index], names=['station_name', 'hour'])\n",
    "station_hourly = station_hourly.set_index(['station_name', 'hour']).reindex(full_index)\n",
    "station_hourly['departures'] = station_hourly['departures'].fillna(0)\n",
    "station_hourly['arrivals'] = station_hourly['arrivals'].fillna(0)\n",
    "station_hourly = station_hourly.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather = pd.read_parquet(\"data/processed/weather_hourly_all_locations_2023.parquet\")\n",
    "hourly_weather[\"date\"] = pd.to_datetime(hourly_weather[\"date\"], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add station name to weather\n",
    "merged_df = pd.merge(hourly_weather, station_data[['LATITUDE', 'LONGITUDE', 'NAME']],\n",
    "                     left_on=['latitude', 'longitude'], right_on=['LATITUDE', 'LONGITUDE'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This seems useless, but is important for the below join to work!\n",
    "station_hourly[\"hour\"] = pd.to_datetime(station_hourly[\"hour\"],utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hourly bike data to station name and weather\n",
    "station_weather_data = pd.merge(station_hourly, merged_df,\n",
    "                                left_on=[\"station_name\", \"hour\"],\n",
    "                                right_on=[\"NAME\", \"date\"],\n",
    "                                # important to left join here as we do not have weather data for the nights\n",
    "                                # inner join would thus throw away 400 hours of activity at night time\n",
    "                                how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally combine with the general data we have on the stations\n",
    "combined_data_final = pd.merge(station_weather_data, station_data, left_on=[\"station_name\"],\n",
    "                                right_on=[\"NAME\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_final = combined_data_final.drop(columns=['date', \"location_id\", \"latitude\", \"longitude\", \"LATITUDE_x\", \"LONGITUDE_x\", 'NAME_x', \"X\", \"Y\", \"NAME_y\", \"STATION_ID\",\"GIS_LAST_MOD_DTTM\", \"OBJECTID\", \"STATION_STATUS\", \"EIGHTD_HAS_KEY_DISPENSER\", \"LAST_REPORTED\",\"NUM_DOCKS_DISABLED\", \"NUM_BIKES_DISABLED\", \"IOS\", \"ANDROID\", \"ELECTRIC_BIKE_SURCHARGE_WAIVER\", 'STATION_TYPE', 'IS_INSTALLED', 'IS_RETURNING', 'IS_RENTING', 'RENTAL_METHODS', 'REGION_ID', 'REGION_NAME', 'GIS_ID'])\n",
    "combined_data_final.columns = combined_data_final.columns.str.lower()\n",
    "combined_data_final = combined_data_final.rename(columns={\n",
    "    'latitude_y': 'latitude',\n",
    "    'longitude_y': 'longitude'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features (Time Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = combined_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holiday\n",
    "import holidays\n",
    "hol = holidays.UnitedStates(years=2023)\n",
    "holiday_dates = set(hol.keys())\n",
    "df_full['isHoliday'] = df_full['hour'].dt.date.isin(holiday_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekdays\n",
    "df_full['weekday'] = df_full['hour'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Night\n",
    "df_full['night'] = df_full['hour'].dt.hour.apply(lambda h: h >= 21 or h < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worktime\n",
    "df_full['workhours'] = (\n",
    "    df_full['hour'].dt.hour.between(8, 16) &\n",
    "    df_full['weekday'].between(0, 4) &\n",
    "    (~df_full['isHoliday'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commute (2 hours before and after start and end of worktime)\n",
    "df_full['commute'] = (\n",
    "    df_full['hour'].dt.hour.between(6, 10) | df_full['hour'].dt.hour.between(15, 19) &\n",
    "    df_full['weekday'].between(0, 4) &\n",
    "    (~df_full['isHoliday'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['free'] = (\n",
    "    df_full['weekday'].between(5, 6) |\n",
    "    df_full['isHoliday']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['day'] = df_full['hour'].dt.day\n",
    "df_full['month'] = df_full['hour'].dt.month\n",
    "df_full['year'] = df_full['hour'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features (Station Based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pro Station: average delta / average arrivals / average depratures + für alles varianz/sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"delta\"] = df_full[\"arrivals\"] - df_full[\"departures\"]\n",
    "\n",
    "df_full['var_delta_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['delta']\n",
    "      .transform('var')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['avg_delta_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['delta']\n",
    "      .transform('mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['avg_arrivals_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .transform('mean')\n",
    ")\n",
    "df_full['avg_departures_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['departures']\n",
    "      .transform('mean')\n",
    ")\n",
    "df_full['var_arrivals_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .transform('var')\n",
    ")\n",
    "df_full['var_departures_station_total'] = (\n",
    "    df_full\n",
    "      .groupby('station_name')['departures']\n",
    "      .transform('var')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacht\n",
    "night_stats = (\n",
    "    df_full[df_full['night']]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_night='mean', var_delta_station_night='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')\n",
    "\n",
    "night_stats = (\n",
    "    df_full[df_full['night']]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_night='mean', var_arrivals_station_night='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "night_stats = (\n",
    "    df_full[df_full['night']]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_night='mean', var_departures_station_night='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicht nacht\n",
    "night_stats = (\n",
    "    df_full[df_full['night'] == False]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_nonnight='mean', var_delta_station_nonnight='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')\n",
    "\n",
    "night_stats = (\n",
    "    df_full[df_full['night'] == False]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_nonnight='mean', var_arrivals_station_nonnight='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "night_stats = (\n",
    "    df_full[df_full['night'] == False]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_nonnight='mean', var_departures_station_nonnight='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(night_stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feiertage\n",
    "stats = (\n",
    "    df_full[df_full['isHoliday']]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_holiday='mean', var_delta_station_holiday='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['isHoliday']]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_holiday='mean', var_arrivals_station_holiday='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['isHoliday']]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_holiday='mean', var_departures_station_holiday='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commute\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['commute']]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_commute='mean', var_delta_station_commute='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['commute']]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_commute='mean', var_arrivals_station_commute='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['commute']]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_commute='mean', var_departures_station_commute='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['free']]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_free='mean', var_delta_station_free='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['free']]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_free='mean', var_arrivals_station_free='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['free']]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_free='mean', var_departures_station_free='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average delta für stunden mit niederschlag (precipitation > 0 oder windgeschwindigkeit über 10)?\n",
    "\n",
    "mask = (df_full['precipitation'] > 0) | (df_full['wind_speed_10m'] > 15)\n",
    "\n",
    "stats = (\n",
    "    df_full[mask]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_delta_station_unfriendly_weather='mean', var_delta_station_unfriendly_weather='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[mask]\n",
    "      .groupby('station_name')['arrivals']\n",
    "      .agg(avg_arrivals_station_unfriendly_weather='mean', var_arrivals_station_unfriendly_weather='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "\n",
    "stats = (\n",
    "    df_full[mask]\n",
    "      .groupby('station_name')['departures']\n",
    "      .agg(avg_departures_station_unfriendly_weather='mean', var_departures_station_unfriendly_weather='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['sum'] = df_full[\"arrivals\"] + df_full[\"departures\"]\n",
    "\n",
    "stats = (\n",
    "    df_full\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station='mean', var_sum_station='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['night']]\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station_night='mean', var_sum_station_night='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['night'] == False]\n",
    "      .groupby('station_name')['delta']\n",
    "      .agg(avg_sum_station_nonnight='mean', var_sum_station_nonnight='var')\n",
    "      .reset_index()\n",
    ")\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['isHoliday']]\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station_holiday='mean', var_sum_station_holiday='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['commute']]\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station_commute='mean', var_sum_station_commute='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "stats = (\n",
    "    df_full[df_full['free']]\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station_free='mean', var_sum_station_free='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n",
    "\n",
    "mask = (df_full['precipitation'] > 0) | (df_full['wind_speed_10m'] > 15)\n",
    "\n",
    "stats = (\n",
    "    df_full[mask]\n",
    "      .groupby('station_name')['sum']\n",
    "      .agg(avg_sum_station_unfriendly_weather='mean', var_sum_station_unfriendly_weather='var')\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_full = df_full.merge(stats, on='station_name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_parquet(\"data/final/df.parquet\", compression='brotli')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
