{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf8e954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, PoissonRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "import pymc as pm\n",
    "import datetime\n",
    "import os\n",
    "import arviz as az\n",
    "import pickle\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"rocket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af7147",
   "metadata": {},
   "source": [
    "# CONFIG\n",
    "\n",
    "**Set sample to False if you want to run algos on entire dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0561453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'sample': False,\n",
    "    'sample_months': 1, # how many months to sample (for development)\n",
    "    'choose_month': 5, # month to choose for sampling // Note: overrides sample_months\n",
    "    'top_n_clusters': 8, # how many clusters to train (upper bound)\n",
    "    # For now, this is only implemented for the whole cluster models for brevity. \n",
    "    'start_at_cluster': 3, # all clusters with an id smaller than this value will be skipped! (lower bound to the line above) \n",
    "    'random_state': 123,\n",
    "    'target_col': 'departures',\n",
    "    'n_jobs': 4,  # gridsearch parallelization, might need to adjust based on your system\n",
    "    'ts_splits': 5, # TimeSeriesSplit number of splits\n",
    "    'ts_gap': 48,  # 2-day gap\n",
    "    'visualize_clusters': False\n",
    "}\n",
    "\n",
    "FEATURE_COLS = {\n",
    "    'categorical': ['isHoliday', 'has_kiosk', 'weather_cluster', 'workhours', 'commute', 'free', 'night'],\n",
    "    'drop': ['sum', 'weather_code', 'timestamp', 'station_name', 'arrivals', 'num_docks_available', 'num_ebikes_available', 'capacity', 'cluster', 'sunset', 'sunrise', 'year', 'hour_extract', 'precipitation', 'wind_gusts_10m', 'dayofyear', 'dayofweek', 'delta'],\n",
    "    'time': ['weekday', 'day', 'month', 'hour']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95c97e",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951f53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/final/df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e326de",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS[\"drop\"] = FEATURE_COLS[\"drop\"] + [col for col in df.columns if (col.startswith(\"var\") or col.startswith(\"avg\"))]\n",
    "\n",
    "# All remaining columns are considered numerical\n",
    "FEATURE_COLS['numerical'] = [col for col in df.columns if col not in ([CONFIG['target_col']] + FEATURE_COLS['categorical'] + FEATURE_COLS['drop'] + FEATURE_COLS['time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70fd33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6464880, 94)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056ca495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCE DATASET SIZE FOR DEVELOPMENT\n",
    "if CONFIG['sample']:\n",
    "    if CONFIG['choose_month'] is not None:\n",
    "        df = df[df['timestamp'].dt.month == CONFIG['choose_month']]\n",
    "        print(f'Chosen month: {CONFIG[\"choose_month\"]}')\n",
    "    else:\n",
    "        months = df['timestamp'].dt.month.unique()\n",
    "        random_month = random.sample(list(months), CONFIG['sample_months'])\n",
    "        df = df[df['timestamp'].dt.month.isin(random_month)]\n",
    "        print(f'Sampled {CONFIG[\"sample_months\"]} month(s): {random_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e142c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hour",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "departures",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "arrivals",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_extract",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "temperature_2m",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "weather_code",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "rain",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "precipitation",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "snowfall",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cloud_cover",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "wind_gusts_10m",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "wind_speed_10m",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "sunrise",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sunset",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weather_cluster",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_docks_available",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_bikes_available",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_ebikes_available",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_kiosk",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "isHoliday",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "weekday",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "night",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "workhours",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "commute",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "free",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "day",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "dayofweek",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "dayofyear",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "delta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_delta_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_delta_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_arrivals_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_arrivals_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_departures_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_departures_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_night",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_nonnight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_holiday",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_commute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sum_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_sum_station_unfriendly_weather",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cluster",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2a1fdba7-b31c-4fc6-a050-632ce32bb7e0",
       "rows": [
        [
         "0",
         "10th & E St NW",
         "0",
         "0.0",
         "0.0",
         "0",
         "11.936",
         "51.0",
         "0.2",
         "0.2",
         "0.0",
         "20.0",
         "17.28",
         "8.473393",
         "1672576012.0",
         "1672610195.0",
         "precipitation",
         "1",
         "12",
         "6",
         "YES",
         "15",
         "38.895914",
         "-77.026064",
         "True",
         "6",
         "True",
         "False",
         "False",
         "True",
         "1",
         "1",
         "2023",
         "6",
         "1",
         "2023-01-01 00:00:00+00:00",
         "0.0",
         "4.696688858762673",
         "0.09400638103919781",
         "1.3966499544211486",
         "1.3026435733819508",
         "4.562992764519648",
         "4.2928978540282206",
         "-0.14068672136128837",
         "1.0552772182400385",
         "0.24096019446976602",
         "0.5483035154363141",
         "0.38164691583105437",
         "1.0907755239258927",
         "0.23482224247948952",
         "6.82923941496837",
         "2.090063810391978",
         "5.689917665511752",
         "1.8552415679124885",
         "5.40026655815509",
         "0.1794871794871795",
         "4.044851183114849",
         "1.419871794871795",
         "4.733108665182616",
         "1.2403846153846154",
         "4.7812577294088525",
         "0.41449934980494146",
         "7.8557766923572885",
         "2.203511053315995",
         "6.254504741666402",
         "1.7890117035110533",
         "6.152217429456481",
         "0.14870689655172414",
         "3.7493479499919458",
         "1.3178879310344827",
         "4.413822918086413",
         "1.1691810344827587",
         "3.7625999758385196",
         "-0.060723514211886306",
         "4.250080992889332",
         "1.2454780361757105",
         "3.694992468496267",
         "1.306201550387597",
         "4.05742813342284",
         "0.0",
         "2.6992935278030994",
         "13.015092378333021",
         "0.6226071103008204",
         "2.222880860484382",
         "3.9453053783044667",
         "15.351129032365286",
         "2.66025641025641",
         "14.983881606068095",
         "3.9925227568270483",
         "16.957667649888478",
         "2.4870689655172415",
         "12.6034978378579",
         "2.5516795865633073",
         "11.25476021094892",
         "5"
        ],
        [
         "1",
         "10th & E St NW",
         "1",
         "0.0",
         "0.0",
         "1",
         "11.486",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "18.359999",
         "10.1376915",
         "1672576012.0",
         "1672610195.0",
         "clear_and_cloudy",
         "1",
         "12",
         "6",
         "YES",
         "15",
         "38.895914",
         "-77.026064",
         "True",
         "6",
         "True",
         "False",
         "False",
         "True",
         "1",
         "1",
         "2023",
         "6",
         "1",
         "2023-01-01 01:00:00+00:00",
         "0.0",
         "4.696688858762673",
         "0.09400638103919781",
         "1.3966499544211486",
         "1.3026435733819508",
         "4.562992764519648",
         "4.2928978540282206",
         "-0.14068672136128837",
         "1.0552772182400385",
         "0.24096019446976602",
         "0.5483035154363141",
         "0.38164691583105437",
         "1.0907755239258927",
         "0.23482224247948952",
         "6.82923941496837",
         "2.090063810391978",
         "5.689917665511752",
         "1.8552415679124885",
         "5.40026655815509",
         "0.1794871794871795",
         "4.044851183114849",
         "1.419871794871795",
         "4.733108665182616",
         "1.2403846153846154",
         "4.7812577294088525",
         "0.41449934980494146",
         "7.8557766923572885",
         "2.203511053315995",
         "6.254504741666402",
         "1.7890117035110533",
         "6.152217429456481",
         "0.14870689655172414",
         "3.7493479499919458",
         "1.3178879310344827",
         "4.413822918086413",
         "1.1691810344827587",
         "3.7625999758385196",
         "-0.060723514211886306",
         "4.250080992889332",
         "1.2454780361757105",
         "3.694992468496267",
         "1.306201550387597",
         "4.05742813342284",
         "0.0",
         "2.6992935278030994",
         "13.015092378333021",
         "0.6226071103008204",
         "2.222880860484382",
         "3.9453053783044667",
         "15.351129032365286",
         "2.66025641025641",
         "14.983881606068095",
         "3.9925227568270483",
         "16.957667649888478",
         "2.4870689655172415",
         "12.6034978378579",
         "2.5516795865633073",
         "11.25476021094892",
         "5"
        ],
        [
         "2",
         "10th & E St NW",
         "2",
         "0.0",
         "0.0",
         "2",
         "11.036",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "4.0",
         "21.24",
         "11.440978",
         "1672576012.0",
         "1672610195.0",
         "clear_and_cloudy",
         "1",
         "12",
         "6",
         "YES",
         "15",
         "38.895914",
         "-77.026064",
         "True",
         "6",
         "True",
         "False",
         "False",
         "True",
         "1",
         "1",
         "2023",
         "6",
         "1",
         "2023-01-01 02:00:00+00:00",
         "0.0",
         "4.696688858762673",
         "0.09400638103919781",
         "1.3966499544211486",
         "1.3026435733819508",
         "4.562992764519648",
         "4.2928978540282206",
         "-0.14068672136128837",
         "1.0552772182400385",
         "0.24096019446976602",
         "0.5483035154363141",
         "0.38164691583105437",
         "1.0907755239258927",
         "0.23482224247948952",
         "6.82923941496837",
         "2.090063810391978",
         "5.689917665511752",
         "1.8552415679124885",
         "5.40026655815509",
         "0.1794871794871795",
         "4.044851183114849",
         "1.419871794871795",
         "4.733108665182616",
         "1.2403846153846154",
         "4.7812577294088525",
         "0.41449934980494146",
         "7.8557766923572885",
         "2.203511053315995",
         "6.254504741666402",
         "1.7890117035110533",
         "6.152217429456481",
         "0.14870689655172414",
         "3.7493479499919458",
         "1.3178879310344827",
         "4.413822918086413",
         "1.1691810344827587",
         "3.7625999758385196",
         "-0.060723514211886306",
         "4.250080992889332",
         "1.2454780361757105",
         "3.694992468496267",
         "1.306201550387597",
         "4.05742813342284",
         "0.0",
         "2.6992935278030994",
         "13.015092378333021",
         "0.6226071103008204",
         "2.222880860484382",
         "3.9453053783044667",
         "15.351129032365286",
         "2.66025641025641",
         "14.983881606068095",
         "3.9925227568270483",
         "16.957667649888478",
         "2.4870689655172415",
         "12.6034978378579",
         "2.5516795865633073",
         "11.25476021094892",
         "5"
        ],
        [
         "3",
         "10th & E St NW",
         "3",
         "1.0",
         "0.0",
         "3",
         "10.786",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "34.0",
         "21.599998",
         "12.224107",
         "1672576012.0",
         "1672610195.0",
         "clear_and_cloudy",
         "1",
         "12",
         "6",
         "YES",
         "15",
         "38.895914",
         "-77.026064",
         "True",
         "6",
         "True",
         "False",
         "False",
         "True",
         "1",
         "1",
         "2023",
         "6",
         "1",
         "2023-01-01 03:00:00+00:00",
         "-1.0",
         "4.696688858762673",
         "0.09400638103919781",
         "1.3966499544211486",
         "1.3026435733819508",
         "4.562992764519648",
         "4.2928978540282206",
         "-0.14068672136128837",
         "1.0552772182400385",
         "0.24096019446976602",
         "0.5483035154363141",
         "0.38164691583105437",
         "1.0907755239258927",
         "0.23482224247948952",
         "6.82923941496837",
         "2.090063810391978",
         "5.689917665511752",
         "1.8552415679124885",
         "5.40026655815509",
         "0.1794871794871795",
         "4.044851183114849",
         "1.419871794871795",
         "4.733108665182616",
         "1.2403846153846154",
         "4.7812577294088525",
         "0.41449934980494146",
         "7.8557766923572885",
         "2.203511053315995",
         "6.254504741666402",
         "1.7890117035110533",
         "6.152217429456481",
         "0.14870689655172414",
         "3.7493479499919458",
         "1.3178879310344827",
         "4.413822918086413",
         "1.1691810344827587",
         "3.7625999758385196",
         "-0.060723514211886306",
         "4.250080992889332",
         "1.2454780361757105",
         "3.694992468496267",
         "1.306201550387597",
         "4.05742813342284",
         "1.0",
         "2.6992935278030994",
         "13.015092378333021",
         "0.6226071103008204",
         "2.222880860484382",
         "3.9453053783044667",
         "15.351129032365286",
         "2.66025641025641",
         "14.983881606068095",
         "3.9925227568270483",
         "16.957667649888478",
         "2.4870689655172415",
         "12.6034978378579",
         "2.5516795865633073",
         "11.25476021094892",
         "5"
        ],
        [
         "4",
         "10th & E St NW",
         "4",
         "0.0",
         "0.0",
         "4",
         "10.536",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "18.0",
         "27.359999",
         "15.175612",
         "1672576012.0",
         "1672610195.0",
         "clear_and_cloudy",
         "1",
         "12",
         "6",
         "YES",
         "15",
         "38.895914",
         "-77.026064",
         "True",
         "6",
         "True",
         "False",
         "False",
         "True",
         "1",
         "1",
         "2023",
         "6",
         "1",
         "2023-01-01 04:00:00+00:00",
         "0.0",
         "4.696688858762673",
         "0.09400638103919781",
         "1.3966499544211486",
         "1.3026435733819508",
         "4.562992764519648",
         "4.2928978540282206",
         "-0.14068672136128837",
         "1.0552772182400385",
         "0.24096019446976602",
         "0.5483035154363141",
         "0.38164691583105437",
         "1.0907755239258927",
         "0.23482224247948952",
         "6.82923941496837",
         "2.090063810391978",
         "5.689917665511752",
         "1.8552415679124885",
         "5.40026655815509",
         "0.1794871794871795",
         "4.044851183114849",
         "1.419871794871795",
         "4.733108665182616",
         "1.2403846153846154",
         "4.7812577294088525",
         "0.41449934980494146",
         "7.8557766923572885",
         "2.203511053315995",
         "6.254504741666402",
         "1.7890117035110533",
         "6.152217429456481",
         "0.14870689655172414",
         "3.7493479499919458",
         "1.3178879310344827",
         "4.413822918086413",
         "1.1691810344827587",
         "3.7625999758385196",
         "-0.060723514211886306",
         "4.250080992889332",
         "1.2454780361757105",
         "3.694992468496267",
         "1.306201550387597",
         "4.05742813342284",
         "0.0",
         "2.6992935278030994",
         "13.015092378333021",
         "0.6226071103008204",
         "2.222880860484382",
         "3.9453053783044667",
         "15.351129032365286",
         "2.66025641025641",
         "14.983881606068095",
         "3.9925227568270483",
         "16.957667649888478",
         "2.4870689655172415",
         "12.6034978378579",
         "2.5516795865633073",
         "11.25476021094892",
         "5"
        ]
       ],
       "shape": {
        "columns": 94,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>hour</th>\n",
       "      <th>departures</th>\n",
       "      <th>arrivals</th>\n",
       "      <th>hour_extract</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>rain</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>...</th>\n",
       "      <th>var_sum_station_nonnight</th>\n",
       "      <th>avg_sum_station_holiday</th>\n",
       "      <th>var_sum_station_holiday</th>\n",
       "      <th>avg_sum_station_commute</th>\n",
       "      <th>var_sum_station_commute</th>\n",
       "      <th>avg_sum_station_free</th>\n",
       "      <th>var_sum_station_free</th>\n",
       "      <th>avg_sum_station_unfriendly_weather</th>\n",
       "      <th>var_sum_station_unfriendly_weather</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10th &amp; E St NW</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.936</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.351129</td>\n",
       "      <td>2.660256</td>\n",
       "      <td>14.983882</td>\n",
       "      <td>3.992523</td>\n",
       "      <td>16.957668</td>\n",
       "      <td>2.487069</td>\n",
       "      <td>12.603498</td>\n",
       "      <td>2.55168</td>\n",
       "      <td>11.25476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10th &amp; E St NW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.351129</td>\n",
       "      <td>2.660256</td>\n",
       "      <td>14.983882</td>\n",
       "      <td>3.992523</td>\n",
       "      <td>16.957668</td>\n",
       "      <td>2.487069</td>\n",
       "      <td>12.603498</td>\n",
       "      <td>2.55168</td>\n",
       "      <td>11.25476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10th &amp; E St NW</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.351129</td>\n",
       "      <td>2.660256</td>\n",
       "      <td>14.983882</td>\n",
       "      <td>3.992523</td>\n",
       "      <td>16.957668</td>\n",
       "      <td>2.487069</td>\n",
       "      <td>12.603498</td>\n",
       "      <td>2.55168</td>\n",
       "      <td>11.25476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10th &amp; E St NW</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.351129</td>\n",
       "      <td>2.660256</td>\n",
       "      <td>14.983882</td>\n",
       "      <td>3.992523</td>\n",
       "      <td>16.957668</td>\n",
       "      <td>2.487069</td>\n",
       "      <td>12.603498</td>\n",
       "      <td>2.55168</td>\n",
       "      <td>11.25476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10th &amp; E St NW</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.351129</td>\n",
       "      <td>2.660256</td>\n",
       "      <td>14.983882</td>\n",
       "      <td>3.992523</td>\n",
       "      <td>16.957668</td>\n",
       "      <td>2.487069</td>\n",
       "      <td>12.603498</td>\n",
       "      <td>2.55168</td>\n",
       "      <td>11.25476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_name  hour  departures  arrivals  hour_extract  temperature_2m  \\\n",
       "0  10th & E St NW     0         0.0       0.0             0          11.936   \n",
       "1  10th & E St NW     1         0.0       0.0             1          11.486   \n",
       "2  10th & E St NW     2         0.0       0.0             2          11.036   \n",
       "3  10th & E St NW     3         1.0       0.0             3          10.786   \n",
       "4  10th & E St NW     4         0.0       0.0             4          10.536   \n",
       "\n",
       "   weather_code  rain  precipitation  snowfall  ...  var_sum_station_nonnight  \\\n",
       "0          51.0   0.2            0.2       0.0  ...                 15.351129   \n",
       "1           0.0   0.0            0.0       0.0  ...                 15.351129   \n",
       "2           0.0   0.0            0.0       0.0  ...                 15.351129   \n",
       "3           1.0   0.0            0.0       0.0  ...                 15.351129   \n",
       "4           0.0   0.0            0.0       0.0  ...                 15.351129   \n",
       "\n",
       "   avg_sum_station_holiday  var_sum_station_holiday  avg_sum_station_commute  \\\n",
       "0                 2.660256                14.983882                 3.992523   \n",
       "1                 2.660256                14.983882                 3.992523   \n",
       "2                 2.660256                14.983882                 3.992523   \n",
       "3                 2.660256                14.983882                 3.992523   \n",
       "4                 2.660256                14.983882                 3.992523   \n",
       "\n",
       "   var_sum_station_commute avg_sum_station_free  var_sum_station_free  \\\n",
       "0                16.957668             2.487069             12.603498   \n",
       "1                16.957668             2.487069             12.603498   \n",
       "2                16.957668             2.487069             12.603498   \n",
       "3                16.957668             2.487069             12.603498   \n",
       "4                16.957668             2.487069             12.603498   \n",
       "\n",
       "   avg_sum_station_unfriendly_weather  var_sum_station_unfriendly_weather  \\\n",
       "0                             2.55168                            11.25476   \n",
       "1                             2.55168                            11.25476   \n",
       "2                             2.55168                            11.25476   \n",
       "3                             2.55168                            11.25476   \n",
       "4                             2.55168                            11.25476   \n",
       "\n",
       "  cluster  \n",
       "0       5  \n",
       "1       5  \n",
       "2       5  \n",
       "3       5  \n",
       "4       5  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee707dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline over all time cluster 0: 2.316139385547197\n",
      "Baseline over all time cluster 1: 1.104808472655983\n",
      "Baseline over all time cluster 2: 0.4637198876281428\n",
      "Baseline over all time cluster 3: 0.7864280404968053\n",
      "Baseline over all time cluster 4: 3.5115909397967626\n",
      "Baseline over all time cluster 5: 2.5969880093352313\n",
      "Baseline over all time cluster 6: 4.125818477787311\n",
      "Baseline over all time cluster 7: 2.5778118929144425\n",
      "Baseline over all time cluster 8: 0.5381255872385102\n",
      "Baseline over all time cluster 9: 0.6125158954085695\n",
      "---\n",
      "Baseline over all time whole city: 554.5587950067702\n",
      "---\n",
      "Baseline over 10-20 may cluster 0: 2.6057317658438466\n",
      "Baseline over 10-20 may cluster 1: 1.2490472559591361\n",
      "Baseline over 10-20 may cluster 2: 0.5400893375025043\n",
      "Baseline over 10-20 may cluster 3: 0.9421146043436236\n",
      "Baseline over 10-20 may cluster 4: 4.0827457833317435\n",
      "Baseline over 10-20 may cluster 5: 2.955754414659583\n",
      "Baseline over 10-20 may cluster 6: 4.672602181193581\n",
      "Baseline over 10-20 may cluster 7: 2.9818686094528717\n",
      "Baseline over 10-20 may cluster 8: 0.5943547558130378\n",
      "Baseline over 10-20 may cluster 9: 0.6921725406377649\n",
      "Baseline over 21-30 may cluster 0: 2.494923005745408\n",
      "Baseline over 21-30 may cluster 1: 1.2878553601128617\n",
      "Baseline over 21-30 may cluster 2: 0.5408812193433232\n",
      "Baseline over 21-30 may cluster 3: 0.880753256987557\n",
      "Baseline over 21-30 may cluster 4: 4.288615420181929\n",
      "Baseline over 21-30 may cluster 5: 2.982620111122556\n",
      "Baseline over 21-30 may cluster 6: 4.49420176030912\n",
      "Baseline over 21-30 may cluster 7: 2.758421448743627\n",
      "Baseline over 21-30 may cluster 8: 0.6145233021528874\n",
      "Baseline over 21-30 may cluster 9: 0.6666198485433135\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do we need to update this to conform with the \"primary\" train-test-split? (The one at the very top)\n",
    "# Baseline-Performance for 0-heavy Data:\n",
    "for i in range(0,10):\n",
    "    df_cluster_subset = df[df[\"cluster\"]==i]\n",
    "    baseline = np.sqrt((sum(df_cluster_subset[\"departures\"]**2))/len(df_cluster_subset))\n",
    "    print(f\"Baseline over all time cluster {i}: {baseline}\")\n",
    "print(\"---\")\n",
    "baseline_citywide_aggregate_df = df[[\"departures\",\"hour\",\"day\", \"month\"]].copy().groupby(['hour', 'day', 'month'], as_index=False)['departures'].sum()\n",
    "# Filter out rows where month == 12 and hour > 15, as we do not have weather data for these so they get implicitly dropped later on\n",
    "baseline_citywide_aggregate_df = baseline_citywide_aggregate_df[~((baseline_citywide_aggregate_df['month'] == 12) & (baseline_citywide_aggregate_df['hour'] > 15))]\n",
    "baseline = np.sqrt((sum(baseline_citywide_aggregate_df[\"departures\"]**2))/len(baseline_citywide_aggregate_df))\n",
    "print(f\"Baseline over all time whole city: {baseline}\")\n",
    "print(\"---\")\n",
    "df_may_subset = df[(df[\"month\"]==5) & (df[\"day\"]>=10) & (df[\"day\"]<=20)].copy()\n",
    "for i in range(0,10):\n",
    "    df_cluster_subset = df_may_subset[df_may_subset[\"cluster\"]==i]\n",
    "    baseline = np.sqrt((sum(df_cluster_subset[\"departures\"]**2))/len(df_cluster_subset))\n",
    "    print(f\"Baseline over 10-20 may cluster {i}: {baseline}\")\n",
    "df_may_subset = df[(df[\"month\"]==5) & (df[\"day\"]>=21) & (df[\"day\"]<=30)].copy()\n",
    "for i in range(0,10):\n",
    "    df_cluster_subset = df_may_subset[df_may_subset[\"cluster\"]==i]\n",
    "    baseline = np.sqrt((sum(df_cluster_subset[\"departures\"]**2))/len(df_cluster_subset))\n",
    "    print(f\"Baseline over 21-30 may cluster {i}: {baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85705d37",
   "metadata": {},
   "source": [
    "## Feature sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a6c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical:\n",
      "  - isHoliday\n",
      "  - has_kiosk\n",
      "  - weather_cluster\n",
      "  - workhours\n",
      "  - commute\n",
      "  - free\n",
      "  - night\n",
      "Drop:\n",
      "  - sum\n",
      "  - weather_code\n",
      "  - timestamp\n",
      "  - station_name\n",
      "  - arrivals\n",
      "  - num_docks_available\n",
      "  - num_ebikes_available\n",
      "  - capacity\n",
      "  - cluster\n",
      "  - sunset\n",
      "  - sunrise\n",
      "  - year\n",
      "  - hour_extract\n",
      "  - precipitation\n",
      "  - wind_gusts_10m\n",
      "  - dayofyear\n",
      "  - dayofweek\n",
      "  - delta\n",
      "  - var_delta_station_total\n",
      "  - avg_delta_station_total\n",
      "  - avg_arrivals_station_total\n",
      "  - avg_departures_station_total\n",
      "  - var_arrivals_station_total\n",
      "  - var_departures_station_total\n",
      "  - avg_delta_station_night\n",
      "  - var_delta_station_night\n",
      "  - avg_arrivals_station_night\n",
      "  - var_arrivals_station_night\n",
      "  - avg_departures_station_night\n",
      "  - var_departures_station_night\n",
      "  - avg_delta_station_nonnight\n",
      "  - var_delta_station_nonnight\n",
      "  - avg_arrivals_station_nonnight\n",
      "  - var_arrivals_station_nonnight\n",
      "  - avg_departures_station_nonnight\n",
      "  - var_departures_station_nonnight\n",
      "  - avg_delta_station_holiday\n",
      "  - var_delta_station_holiday\n",
      "  - avg_arrivals_station_holiday\n",
      "  - var_arrivals_station_holiday\n",
      "  - avg_departures_station_holiday\n",
      "  - var_departures_station_holiday\n",
      "  - avg_delta_station_commute\n",
      "  - var_delta_station_commute\n",
      "  - avg_arrivals_station_commute\n",
      "  - var_arrivals_station_commute\n",
      "  - avg_departures_station_commute\n",
      "  - var_departures_station_commute\n",
      "  - avg_delta_station_free\n",
      "  - var_delta_station_free\n",
      "  - avg_arrivals_station_free\n",
      "  - var_arrivals_station_free\n",
      "  - avg_departures_station_free\n",
      "  - var_departures_station_free\n",
      "  - avg_delta_station_unfriendly_weather\n",
      "  - var_delta_station_unfriendly_weather\n",
      "  - avg_arrivals_station_unfriendly_weather\n",
      "  - var_arrivals_station_unfriendly_weather\n",
      "  - avg_departures_station_unfriendly_weather\n",
      "  - var_departures_station_unfriendly_weather\n",
      "  - avg_sum_station\n",
      "  - var_sum_station\n",
      "  - avg_sum_station_night\n",
      "  - var_sum_station_night\n",
      "  - avg_sum_station_nonnight\n",
      "  - var_sum_station_nonnight\n",
      "  - avg_sum_station_holiday\n",
      "  - var_sum_station_holiday\n",
      "  - avg_sum_station_commute\n",
      "  - var_sum_station_commute\n",
      "  - avg_sum_station_free\n",
      "  - var_sum_station_free\n",
      "  - avg_sum_station_unfriendly_weather\n",
      "  - var_sum_station_unfriendly_weather\n",
      "Time:\n",
      "  - weekday\n",
      "  - day\n",
      "  - month\n",
      "  - hour\n",
      "Numerical:\n",
      "  - temperature_2m\n",
      "  - rain\n",
      "  - snowfall\n",
      "  - cloud_cover\n",
      "  - wind_speed_10m\n",
      "  - num_bikes_available\n",
      "  - latitude\n",
      "  - longitude\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for features\n",
    "print(\"Categorical:\\n\" + '\\n'.join(f\"  - {feature_col}\" for feature_col in FEATURE_COLS['categorical']))\n",
    "print(\"Drop:\\n\" + '\\n'.join(f\"  - {feature_col}\" for feature_col in FEATURE_COLS['drop']))\n",
    "print(\"Time:\\n\" + '\\n'.join(f\"  - {feature_col}\" for feature_col in FEATURE_COLS['time']))\n",
    "print(\"Numerical:\\n\" + '\\n'.join(f\"  - {feature_col}\" for feature_col in FEATURE_COLS['numerical']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a22b519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the target variable\n",
    "sns.histplot(df[CONFIG['target_col']])\n",
    "plt.title(f'Distribution of {CONFIG[\"target_col\"]}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6553df3",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738ca232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "def prepare_data(df, target_col, categorical_cols, numerical_cols, time_cols, drop_cols, split_and_datetime = True):\n",
    "    # Drop rows with NaN values\n",
    "    df_clean = df.dropna()\n",
    "    print(f\"Dropped {len(df) - len(df_clean)} rows with NaN values.\")\n",
    "\n",
    "    # Keep datetime for visualization purposes if available\n",
    "    datetime_col = df_clean['timestamp'] if 'timestamp' in df_clean.columns else None\n",
    "    datetime_keeper = df_clean.copy()\n",
    "\n",
    "    # Drop columns defined in drop_cols\n",
    "    df_clean = df_clean.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # Split features and target\n",
    "    X = df_clean[categorical_cols + numerical_cols + time_cols]\n",
    "    y = df_clean[target_col]\n",
    "    \n",
    "    # This is not nice, but its a band-aid one-off solution for the bayesian model\n",
    "    if not split_and_datetime:\n",
    "        return X, y\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=CONFIG['random_state'], shuffle=False)\n",
    "\n",
    "    train_indices = X_train.index\n",
    "    test_indices = X_test.index\n",
    "    datetime_train = datetime_keeper.loc[train_indices, 'timestamp'] if datetime_col is not None else None\n",
    "    datetime_test = datetime_keeper.loc[test_indices, 'timestamp'] if datetime_col is not None else None\n",
    "    datetime_col = [datetime_train, datetime_test] if datetime_train is not None else None\n",
    "   \n",
    "    return X_train, y_train, X_test, y_test, datetime_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb3de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2952 rows with NaN values.\n",
      "Training set:\n",
      "Features shape: (6138831, 19)\n",
      "Target shape: (6138831,)\n"
     ]
    }
   ],
   "source": [
    "# Test-apply data preparation\n",
    "X, y, X_test, y_test, datetime_col = prepare_data(df, CONFIG['target_col'], FEATURE_COLS['categorical'], FEATURE_COLS['numerical'], FEATURE_COLS['time'], FEATURE_COLS['drop'])\n",
    "\n",
    "print(\"Training set:\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows from X:\n",
      "| isHoliday   | has_kiosk   | weather_cluster   | workhours   | commute   | free   | night   |   temperature_2m |   rain |   snowfall |   cloud_cover |   wind_speed_10m |   num_bikes_available |   latitude |   longitude |   weekday |   day |   month |   hour |\n",
      "|:------------|:------------|:------------------|:------------|:----------|:-------|:--------|-----------------:|-------:|-----------:|--------------:|-----------------:|----------------------:|-----------:|------------:|----------:|------:|--------:|-------:|\n",
      "| True        | YES         | precipitation     | False       | False     | True   | True    |           11.936 |    0.2 |          0 |            20 |          8.47339 |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      0 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | False     | True   | True    |           11.486 |    0   |          0 |             0 |         10.1377  |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      1 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | False     | True   | True    |           11.036 |    0   |          0 |             4 |         11.441   |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      2 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | False     | True   | True    |           10.786 |    0   |          0 |            34 |         12.2241  |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      3 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | False     | True   | True    |           10.536 |    0   |          0 |            18 |         15.1756  |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      4 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | False     | True   | True    |           10.136 |    0   |          0 |            81 |         14.5121  |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      5 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | True      | True   | False   |            9.636 |    0   |          0 |            59 |         10.4957  |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      6 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | True      | True   | False   |            8.336 |    0   |          0 |           100 |          7.72953 |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      7 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | True      | True   | False   |            8.236 |    0   |          0 |            98 |          7.51702 |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      8 |\n",
      "| True        | YES         | clear_and_cloudy  | False       | True      | True   | False   |            8.586 |    0   |          0 |            99 |          6.95275 |                    12 |    38.8959 |    -77.0261 |         6 |     1 |       1 |      9 |\n"
     ]
    }
   ],
   "source": [
    "print(\"Head of X (for report):\")\n",
    "print(X.head(10).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set:\")\n",
    "print(f\"Features shape: {X_test.shape}\")\n",
    "print(f\"Target shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20b0e3",
   "metadata": {},
   "source": [
    "# Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b922b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def sin_transformer(period):\n",
    "    def _transform(X_input): # X_input will be a 2D numpy array (n_samples, 1 feature)\n",
    "        # Extract the first (and only) column for calculation\n",
    "        data = X_input[:, 0]\n",
    "        # Perform transformation and ensure output is a 2D column vector\n",
    "        return np.sin(data / period * 2 * np.pi).reshape(-1, 1)\n",
    "\n",
    "    return FunctionTransformer(\n",
    "        _transform,\n",
    "        feature_names_out=\"one-to-one\", # This allows ColumnTransformer to get feature names\n",
    "        validate=True # Ensures input is 2D float numpy array and output is 2D\n",
    "    )\n",
    "\n",
    "def cos_transformer(period):\n",
    "    def _transform(X_input): # X_input will be a 2D numpy array (n_samples, 1 feature)\n",
    "        # Extract the first (and only) column for calculation\n",
    "        data = X_input[:, 0]\n",
    "        # Perform transformation and ensure output is a 2D column vector\n",
    "        return np.cos(data / period * 2 * np.pi).reshape(-1, 1)\n",
    "\n",
    "    return FunctionTransformer(\n",
    "        _transform,\n",
    "        feature_names_out=\"one-to-one\", # This allows ColumnTransformer to get feature names\n",
    "        validate=True # Ensures input is 2D float numpy array and output is 2D\n",
    "    )\n",
    "\n",
    "# Function to create model pipelines for each cluster\n",
    "def create_model_pipelines(categorical_cols, numerical_cols, time_cols, X):\n",
    "    \n",
    "    preprocessor_plain = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    preprocessor_onehot = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('time', OneHotEncoder(handle_unknown='ignore', sparse_output=False), time_cols),\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    # Prepared but currently not in use\n",
    "    preprocessor_sincos = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('sin_month', sin_transformer(12), ['month']),\n",
    "        ('sin_hour', sin_transformer(24), ['hour']),\n",
    "        ('sin_weekday', sin_transformer(7), ['weekday']),\n",
    "        ('cos_month', cos_transformer(12), ['month']),\n",
    "        ('cos_hour', cos_transformer(24), ['hour']),\n",
    "        ('cos_weekday', cos_transformer(7), ['weekday'])\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    numerical_indices = [X.columns.get_loc(c) for c in numerical_cols]\n",
    "\n",
    "    poly_transformer = ColumnTransformer([\n",
    "        (\"poly\", PolynomialFeatures(include_bias=False), numerical_indices)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    # Create pipelines\n",
    "    pipelines = {\n",
    "        'linear': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', LinearRegression())\n",
    "        ]),\n",
    "        \n",
    "        'lasso': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', Lasso(random_state=CONFIG['random_state']))\n",
    "        ]),\n",
    "        \n",
    "        'ridge': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', Ridge(random_state=CONFIG['random_state']))\n",
    "        ]),\n",
    "        'polynomial': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('poly', poly_transformer),\n",
    "            ('regressor', LinearRegression())\n",
    "        ]),\n",
    "        'poisson': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', PoissonRegressor(max_iter=1000))\n",
    "        ]),\n",
    "        'decision_tree': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', DecisionTreeRegressor(random_state=CONFIG['random_state']))\n",
    "        ]),\n",
    "        'random_forest': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', RandomForestRegressor(random_state=CONFIG['random_state']))\n",
    "        ]),\n",
    "        'xgboost': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=CONFIG['random_state']))\n",
    "        ]),\n",
    "        'gbm': Pipeline([\n",
    "            ('preprocessing', 'passthrough'),\n",
    "            ('regressor', GradientBoostingRegressor(random_state=CONFIG['random_state']))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Store preprocessor strategies\n",
    "    preprocessing_strategies = {\n",
    "        'plain': preprocessor_plain,\n",
    "        'onehot': preprocessor_onehot,\n",
    "        'sincos': preprocessor_sincos\n",
    "    }\n",
    "    \n",
    "    preprocessor_plain.strategy_name = 'Plain'\n",
    "    preprocessor_onehot.strategy_name = 'OneHot'  \n",
    "    preprocessor_sincos.strategy_name = 'SinCos'\n",
    "    \n",
    "    return pipelines, preprocessing_strategies\n",
    "\n",
    "# Function to get parameter grids\n",
    "def get_param_grids(preprocessing_strategies):\n",
    "    return {\n",
    "        'linear': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ]\n",
    "            },\n",
    "        \n",
    "        'lasso': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__alpha': np.logspace(-4,4,20),\n",
    "            'regressor__max_iter': [1000, 2000]\n",
    "        },\n",
    "        \n",
    "        'ridge': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__alpha': np.logspace(-4,4,20)\n",
    "        },\n",
    "\n",
    "        'polynomial': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'poly__poly__degree': [2, 3, 4]\n",
    "        },\n",
    "\n",
    "        'poisson': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__alpha': np.logspace(-4,4,20)\n",
    "        },\n",
    "        \n",
    "        'decision_tree': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__max_depth': [3, 5, 10, 20],\n",
    "            'regressor__min_samples_split': [2, 5, 10, 15, 20]\n",
    "        },\n",
    "        \n",
    "        'random_forest': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__n_estimators': [50, 100],\n",
    "            'regressor__max_depth': [10, 20],\n",
    "            'regressor__min_samples_split': [2, 5, 10, 15, 20]\n",
    "        },\n",
    "        \n",
    "        'xgboost': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__n_estimators': [50, 100],\n",
    "            'regressor__max_depth': [3, 6],\n",
    "            'regressor__learning_rate': [0.01, 0.1]\n",
    "        },\n",
    "        \n",
    "        'gbm': {\n",
    "            'preprocessing': [\n",
    "                preprocessing_strategies['plain'],\n",
    "                preprocessing_strategies['onehot'],\n",
    "                preprocessing_strategies['sincos']\n",
    "            ],\n",
    "            'regressor__n_estimators': [50, 100],\n",
    "            'regressor__max_depth': [3, 6],\n",
    "            'regressor__learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f208423",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04542997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(model_name, pipeline, cluster_id):\n",
    "    reg = pipeline.named_steps['regressor']\n",
    "            \n",
    "    feat_names = pipeline.named_steps['preprocessing'].get_feature_names_out()\n",
    "            \n",
    "    # build and sort df\n",
    "    coef_df = (\n",
    "        pd.DataFrame({'feature': feat_names, 'coefficient': reg.coef_})\n",
    "            .assign(abs_coef=lambda df: df.coefficient.abs())\n",
    "            .sort_values('abs_coef', ascending=False)\n",
    "            .drop(columns='abs_coef')\n",
    "        )\n",
    "\n",
    "    # largest coefficients first\n",
    "    coef_df = coef_df[::-1]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(coef_df['coefficient'], coef_df['feature'], s=50, color='C0')\n",
    "    plt.axvline(0, linestyle='--', color='gray')\n",
    "    plt.title(f'{str(model_name).capitalize()} Coefficients (Cluster {cluster_id})')\n",
    "    plt.xlabel('Coefficient value')\n",
    "    plt.tick_params(axis='y', pad=5) # increase space around y ticks\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/training/{cluster_id}_{model_name}_coefficients_model_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "    return coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07299b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model_name, model, X, cluster_id):\n",
    "    # Extract the regressor from pipeline\n",
    "    regressor = None\n",
    "    for step_name, step in model.named_steps.items():\n",
    "        if hasattr(step, 'feature_importances_'):\n",
    "            regressor = step\n",
    "            break\n",
    "    \n",
    "    if regressor is None:\n",
    "        print(f\"Model {model_name} doesn't support feature importance.\")\n",
    "        return\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    try:\n",
    "        # Try to get preprocessed feature names\n",
    "        if 'preprocessing' in model.named_steps and hasattr(model['preprocessing'], 'get_feature_names_out'):\n",
    "            feature_names = model['preprocessing'].get_feature_names_out()\n",
    "        else:\n",
    "            # Fallback to original feature names or indices\n",
    "            feature_names = X.columns if hasattr(X, 'columns') else [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "        \n",
    "        # Ensure the lengths match\n",
    "        if len(feature_names) != len(regressor.feature_importances_):\n",
    "            print(f\"Warning: Feature names length ({len(feature_names)}) doesn't match importances length ({len(regressor.feature_importances_)})\")\n",
    "            # Use indices as fallback\n",
    "            feature_names = [f\"feature_{i}\" for i in range(len(regressor.feature_importances_))]\n",
    "            \n",
    "        # Extract feature importances\n",
    "        importance = regressor.feature_importances_\n",
    "        \n",
    "        # Create DataFrame for better visualization\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importance\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_imp.head(20))\n",
    "        plt.title(f'Feature Importance - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figures/training/{cluster_id}_{model_name}_feature_importances.png')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Feature importance report for {model_name}:\")\n",
    "        print(feature_imp)\n",
    "        \n",
    "        return feature_imp\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting feature importance: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_predictions(model_name, model, X, y, datetime_col, cluster_id):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Create a DataFrame for plotting\n",
    "    pred_df = pd.DataFrame({\n",
    "        'datetime': datetime_col,\n",
    "        'actual': y,\n",
    "        'predicted': y_pred\n",
    "    })\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(sorted(pred_df['datetime']), pred_df['actual'], label='Actual', alpha=0.7)\n",
    "    plt.plot(sorted(pred_df['datetime']), pred_df['predicted'], label='Predicted', alpha=0.7)\n",
    "    plt.title(f'{model_name} - Actual vs Predicted (MSE: {mse:.2f}, R²: {r2:.2f})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if cluster_id == 'may_subset': # Magic happens here, don't question it\n",
    "        plt.savefig(f'figures/training/may_subset/{cluster_id}_{model_name}_actual_vs_predicted.png')\n",
    "    else:\n",
    "        plt.savefig(f'figures/training/{cluster_id}_{model_name}_actual_vs_predicted.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot residuals\n",
    "    pred_df['residual'] = pred_df['actual'] - pred_df['predicted']\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(pred_df['predicted'], pred_df['residual'], alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.title(f'{model_name} - Residuals Plot')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.tight_layout()\n",
    "    if cluster_id == 'may_subset':  \n",
    "        plt.savefig(f'figures/training/may_subset/{cluster_id}_{model_name}_residuals.png')\n",
    "    else:\n",
    "        plt.savefig(f'figures/training/{cluster_id}_{model_name}_residuals.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeModelMetricsOnDisc(name, subset: bool, results, cluster_id):\n",
    "    FILE = \"checkpoints/model_train_checkpointing.csv\"\n",
    "    file_exists = os.path.exists(FILE)\n",
    "\n",
    "    best_params = ' '.join(str(results['best_params']).replace('\\n', '').split())\n",
    "    time_string = '{date:%Y-%m-%d_%H:%M:%S}'.format(date=datetime.datetime.now())\n",
    "\n",
    "    with open(FILE, 'a') as file:\n",
    "        if not file_exists:\n",
    "            file.write(\"timestamp,subset,model,cluster_id,best_params,best_score,rmse,mean_train_score\\n\")\n",
    "        file.write(f\"{time_string},{subset},{name},{cluster_id},\\\"{best_params}\\\",{results['best_score']},{results['rmse']},{results['mean_train_score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a single model\n",
    "def train_evaluate_model(cluster_id, subset:bool, name, pipeline, param_grid, X, y, n_splits=CONFIG['ts_splits']):\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    \n",
    "    # Use TimeSeriesSplit for validation\n",
    "    tscv = TimeSeriesSplit(\n",
    "        n_splits=n_splits,\n",
    "        gap=CONFIG['ts_gap'])\n",
    "    \n",
    "    # GridSearch with time series split\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid,\n",
    "        cv=tscv, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=CONFIG['n_jobs'],\n",
    "        verbose=1,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    if 'preprocessing' in best_params.keys():\n",
    "        if hasattr(best_params['preprocessing'], 'strategy_name'):\n",
    "            preproc_name = best_params['preprocessing'].strategy_name\n",
    "    else:\n",
    "        preproc_name = 'Unknown'\n",
    "    \n",
    "    # Store results\n",
    "    best_model = grid_search.best_estimator_\n",
    "    mean_train_scores = -grid_search.cv_results_['mean_train_score']\n",
    "    mean_train_score = np.mean(mean_train_scores)\n",
    "    result = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': -grid_search.best_score_,  # Convert back to positive MSE\n",
    "        'rmse': np.sqrt(-grid_search.best_score_),\n",
    "        'mean_train_score': mean_train_score,\n",
    "    }\n",
    "    \n",
    "    print(f\"  Best parameters: {result['best_params']}\")\n",
    "    print(f\"  Preprocessing strategy: {preproc_name}\")\n",
    "    print(f\"  MSE: {result['best_score']:.4f}\")\n",
    "    print(f\"  RMSE: {result['rmse']:.4f}\")\n",
    "    print(f\"  Mean Train Score: {mean_train_score}\")\n",
    "    storeModelMetricsOnDisc(name, subset, result, cluster_id)\n",
    "\n",
    "    return best_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875adcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cluster_data(cluster_id, df_processed):\n",
    "\n",
    "    cluster_df = df_processed[df_processed['cluster'] == cluster_id].copy()\n",
    "    return prepare_data(cluster_df, CONFIG['target_col'], FEATURE_COLS['categorical'], FEATURE_COLS['numerical'], FEATURE_COLS['time'], FEATURE_COLS['drop'])\n",
    "\n",
    "def train_cluster_models(cluster_id, X, y, models_to_train, subset: bool):\n",
    "\n",
    "    best_models = {}\n",
    "    results = {}\n",
    "    \n",
    "    pipelines, preprocessing_strategies = create_model_pipelines(FEATURE_COLS['categorical'], FEATURE_COLS['numerical'], FEATURE_COLS['time'], X)\n",
    "    param_grids = get_param_grids(preprocessing_strategies)\n",
    "    \n",
    "    for model_name in models_to_train:\n",
    "        if model_name in pipelines:\n",
    "            best_models[model_name], results[model_name] = train_evaluate_model(\n",
    "                cluster_id, subset, model_name, pipelines[model_name], param_grids[model_name], X, y\n",
    "            )\n",
    "    \n",
    "    return best_models, results\n",
    "\n",
    "def create_comparison_df(results_dict):\n",
    "\n",
    "    comparison = pd.DataFrame({\n",
    "        'Model': list(results_dict.keys()),\n",
    "        'RMSE': [results_dict[m]['rmse'] for m in results_dict.keys()]\n",
    "    }).sort_values('RMSE')\n",
    "    \n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2e498",
   "metadata": {},
   "source": [
    "# Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879e149",
   "metadata": {},
   "source": [
    "## 1. Cluster Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91651622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_to_train_cluster = ['linear', 'lasso', 'ridge', 'polynomial', 'decision_tree', 'xgboost']\n",
    "models_to_train_cluster = ['linear', 'lasso', 'ridge', 'decision_tree', 'xgboost']\n",
    "\n",
    "unique_clusters = sorted(df['cluster'].unique().tolist())\n",
    "print(f\"Found {len(unique_clusters)} clusters: {unique_clusters}\")\n",
    "\n",
    "# # Store cluster results\n",
    "all_cluster_models = {}\n",
    "all_cluster_results = {}\n",
    "all_cluster_comparisons = {}\n",
    "\n",
    "# Train models for each cluster\n",
    "for i, cluster_id in enumerate(unique_clusters):\n",
    "    print(cluster_id)\n",
    "    print(CONFIG['start_at_cluster'])\n",
    "    if cluster_id < CONFIG['start_at_cluster']:\n",
    "        print(cluster_id)\n",
    "        print(CONFIG['start_at_cluster'])\n",
    "        continue\n",
    "    print(f\"\\n{'='*50}\\nProcessing Cluster {cluster_id}\\n{'='*50}\")\n",
    "    \n",
    "    # Get data for this cluster\n",
    "    X_cluster, y_cluster, X_cluster_test, y_cluster_test, datetime_col = prepare_cluster_data(cluster_id, df)\n",
    "    \n",
    "    # Train models\n",
    "    models, results = train_cluster_models(cluster_id, X_cluster, y_cluster, models_to_train_cluster, subset=False)\n",
    "\n",
    "    # Store results\n",
    "    all_cluster_models[cluster_id] = models\n",
    "    all_cluster_results[cluster_id] = results\n",
    "    all_cluster_comparisons[cluster_id] = create_comparison_df(results)\n",
    "            \n",
    "    print(f\"\\nModel Comparison for Cluster {cluster_id}:\")\n",
    "    comparison_cluster = create_comparison_df(results)\n",
    "    print(comparison_cluster)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='RMSE', y='Model', data=comparison_cluster)\n",
    "    plt.title(f'Cluster {cluster_id} - Model Comparison (RMSE - lower is better)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/training/cluster_{cluster_id}_model_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show feature importance for tree-based models\n",
    "    for model_name in ['xgboost', 'random_forest', 'decision_tree']:\n",
    "        if model_name in models:\n",
    "            print(f\"\\nFeature Importance for {model_name} in Cluster {cluster_id}:\")\n",
    "            feature_importance = plot_feature_importance(model_name, models[model_name], X_cluster, cluster_id)\n",
    "\n",
    "    # \"feature importance\" for regression methods\n",
    "    for model_name in ['linear', 'lasso', 'ridge']:\n",
    "        if model_name in models:\n",
    "            print(f\"\\nCoefficients for {model_name} in Cluster {cluster_id}:\")\n",
    "            coefficients = plot_coefficients(model_name, models[model_name], cluster_id)\n",
    "    \n",
    "    # Visualize best model predictions\n",
    "    best_model_name = comparison_cluster['Model'].iloc[0]\n",
    "    print(f\"Best model for Cluster {cluster_id}: {best_model_name} with validation RMSE: {comparison_cluster['RMSE'].iloc[0]:.4f}\")\n",
    "    \n",
    "    # Test best model on test set\n",
    "    y_cluster_pred = models[best_model_name].predict(X_cluster_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_cluster_test, y_cluster_pred))\n",
    "    print(f\"Best model on test set for Cluster {cluster_id}: {best_model_name} with test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    print(f\"\\nVisualizing predictions on test set (5% of data) for {best_model_name} in Cluster {cluster_id}:\")\n",
    "    pred_df = visualize_predictions(best_model_name, models[best_model_name], X_cluster_test, y_cluster_test, datetime_col[1], cluster_id) # datetime_col[1] are times corresponding to test set\n",
    "\n",
    "    if i == CONFIG['top_n_clusters']-1:\n",
    "        print(f\"Reached top {CONFIG['top_n_clusters']} clusters. Stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fe03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of best models across clusters\n",
    "summary_rows = []\n",
    "for cluster_id in all_cluster_comparisons:\n",
    "    best_model = all_cluster_comparisons[cluster_id].iloc[0]\n",
    "    summary_rows.append({\n",
    "        'Cluster': cluster_id,\n",
    "        'Best Model': best_model['Model'],\n",
    "        'RMSE': best_model['RMSE'],\n",
    "    })\n",
    "\n",
    "cluster_summary = pd.DataFrame(summary_rows).sort_values('RMSE')\n",
    "\n",
    "print(\"\\nBest Models by Cluster:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Plot cluster performance comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "cluster_summary_plot = cluster_summary.copy()\n",
    "cluster_summary_plot['Cluster_Model'] = cluster_summary_plot.apply(\n",
    "    lambda x: f\"Cluster {x['Cluster']}: {x['Best Model']}\", axis=1\n",
    ")\n",
    "sns.barplot(x='RMSE', y='Cluster_Model', data=cluster_summary_plot)\n",
    "plt.title('Best Model Performance by Cluster (RMSE - lower is better)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/training/best_model_performance_by_cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b05184",
   "metadata": {},
   "source": [
    "## 2. Citywide Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train_city = ['linear', 'lasso', 'ridge', 'decision_tree', 'xgboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01986065",
   "metadata": {},
   "source": [
    "### Fully Pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "print(f\"Models to train (citywide): {models_to_train_city}\")\n",
    "\n",
    "current_feature_cols_citywide = copy.deepcopy(FEATURE_COLS)\n",
    "\n",
    "if 'cluster' not in current_feature_cols_citywide['drop']:\n",
    "    current_feature_cols_citywide['drop'].append('cluster')\n",
    "    print(\"Appended 'cluster' to drop cols.\")\n",
    "\n",
    "for cat_list_name in ['categorical', 'numerical', 'time']:\n",
    "    if cat_list_name in current_feature_cols_citywide and 'cluster' in current_feature_cols_citywide[cat_list_name]:\n",
    "        current_feature_cols_citywide[cat_list_name].remove('cluster')\n",
    "        print(f\"Removed 'cluster' from {cat_list_name} cols.\")\n",
    "\n",
    "X_city, y_city, X_city_test, y_city_test, datetime_col_city = prepare_data(\n",
    "    df,\n",
    "    CONFIG['target_col'],\n",
    "    current_feature_cols_citywide['categorical'],\n",
    "    current_feature_cols_citywide['numerical'],\n",
    "    current_feature_cols_citywide['time'],\n",
    "    current_feature_cols_citywide['drop']\n",
    ")\n",
    "\n",
    "print(f\"\\nCitywide training set features shape: {X_city.shape}\")\n",
    "print(f\"Citywide training set target shape: {y_city.shape}\")\n",
    "print(f\"Citywide test set features shape: {X_city_test.shape}\")\n",
    "print(f\"Citywide test set target shape: {y_city_test.shape}\")\n",
    "\n",
    "city_best_models = {}\n",
    "city_results = {}\n",
    "\n",
    "pipelines_city, preprocessing_strategies_city = create_model_pipelines(\n",
    "    current_feature_cols_citywide['categorical'],\n",
    "    current_feature_cols_citywide['numerical'],\n",
    "    current_feature_cols_citywide['time'],\n",
    "    X_city\n",
    ")\n",
    "param_grids_city = get_param_grids(preprocessing_strategies_city)\n",
    "\n",
    "print(f\"\\n{'='*50}\\nTraining models for the entire city\\n{'='*50}\")\n",
    "for model_name_item in models_to_train_city:\n",
    "    if model_name_item in pipelines_city:\n",
    "        city_best_models[model_name_item], city_results[model_name_item] = train_evaluate_model(\n",
    "            'citywide',  # Using 'citywide' as pseudo cluster_id\n",
    "            False,\n",
    "            model_name_item,\n",
    "            pipelines_city[model_name_item],\n",
    "            param_grids_city[model_name_item],\n",
    "            X_city,\n",
    "            y_city\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping {model_name_item} as it's not defined in pipelines_city\")\n",
    "\n",
    "# Create and display comparison DataFrame for citywide models\n",
    "if city_results:\n",
    "    city_comparison_df = create_comparison_df(city_results)\n",
    "    print(\"\\nModel Comparison Citywide:\")\n",
    "    print(city_comparison_df)\n",
    "\n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='RMSE', y='Model', data=city_comparison_df.sort_values('RMSE', ascending=True))\n",
    "    plt.title('Citywide Model Comparison (RMSE - lower is better)')\n",
    "    plt.savefig('figures/training/citywide_model_comparison.png')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Show feature importance for tree-based models\n",
    "    for model_name_item in ['xgboost', 'random_forest', 'decision_tree']:\n",
    "        if model_name_item in city_best_models:\n",
    "            print(f\"\\nFeature Importance for {model_name_item} (Citywide):\")\n",
    "            plot_feature_importance(model_name_item, city_best_models[model_name_item], X_city, 'citywide')\n",
    "\n",
    "    # Show coefficients for linear models\n",
    "    for model_name_item in ['linear', 'lasso', 'ridge']:\n",
    "        if model_name_item in city_best_models:\n",
    "            print(f\"\\nCoefficients for {model_name_item} (Citywide):\")\n",
    "            plot_coefficients(model_name_item, city_best_models[model_name_item], 'citywide')\n",
    "    \n",
    "    if not city_comparison_df.empty:\n",
    "        best_city_model_name = city_comparison_df['Model'].iloc[0]\n",
    "        best_city_model_rmse_val = city_comparison_df['RMSE'].iloc[0]\n",
    "        print(f\"\\nBest model for the City (based on validation RMSE): {best_city_model_name} with Validation RMSE: {best_city_model_rmse_val:.4f}\")\n",
    "\n",
    "        # Test best model on the citywide test set\n",
    "        y_city_pred_test = city_best_models[best_city_model_name].predict(X_city_test)\n",
    "        city_test_rmse = np.sqrt(mean_squared_error(y_city_test, y_city_pred_test))\n",
    "        r2_city_test = r2_score(y_city_test, y_city_pred_test)\n",
    "        print(f\"Best city model ({best_city_model_name}) on Test Set: RMSE: {city_test_rmse:.4f}, R²: {r2_city_test:.4f}\")\n",
    "\n",
    "        print(f\"\\nVisualizing predictions on test set for {best_city_model_name} (Citywide):\")\n",
    "        # datetime_col_city[0] is train datetime, datetime_col_city[1] is test datetime\n",
    "        visualize_predictions(best_city_model_name, city_best_models[best_city_model_name], X_city_test, y_city_test, datetime_col_city[1], 'citywide')\n",
    "    else:\n",
    "        print(\"No models for citywide\")\n",
    "else:\n",
    "    print(\"No results for citywide\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba511f",
   "metadata": {},
   "source": [
    "### Aggregate (City-Wide - the real deal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b151f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "print(f\"Models to train (citywide): {models_to_train_city}\")\n",
    "\n",
    "current_feature_cols_citywide = copy.deepcopy(FEATURE_COLS)\n",
    "\n",
    "if 'cluster' not in current_feature_cols_citywide['drop']:\n",
    "    current_feature_cols_citywide['drop'].append('cluster')\n",
    "    print(\"Appended 'cluster' to drop cols.\")\n",
    "\n",
    "for cat_list_name in ['categorical', 'numerical', 'time']:\n",
    "    if cat_list_name in current_feature_cols_citywide and 'cluster' in current_feature_cols_citywide[cat_list_name]:\n",
    "        current_feature_cols_citywide[cat_list_name].remove('cluster')\n",
    "        print(f\"Removed 'cluster' from {cat_list_name} cols.\")\n",
    "\n",
    "current_feature_cols_citywide['categorical'].remove('has_kiosk')\n",
    "current_feature_cols_citywide['categorical'].remove('weather_cluster')\n",
    "current_feature_cols_citywide['numerical'].remove('num_bikes_available')\n",
    "current_feature_cols_citywide['numerical'].remove('latitude')\n",
    "current_feature_cols_citywide['numerical'].remove('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = ['hour', 'day', 'month']\n",
    "\n",
    "cols_to_average = ['temperature_2m', 'rain', 'snowfall', 'cloud_cover', 'wind_speed_10m']\n",
    "cols_to_pick_first = ['weekday', 'isHoliday', 'workhours', 'commute','free','night', 'timestamp']\n",
    "\n",
    "# Build aggregation dictionary\n",
    "agg_dict = {\n",
    "    'departures': 'sum',\n",
    "    **{col: 'mean' for col in cols_to_average},\n",
    "    **{col: 'first' for col in cols_to_pick_first}\n",
    "}\n",
    "\n",
    "# Apply aggregation\n",
    "aggregated_df = df.groupby(group_keys).agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc04c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_city, y_city, X_city_test, y_city_test, datetime_col_city = prepare_data(\n",
    "    aggregated_df,\n",
    "    CONFIG['target_col'],\n",
    "    current_feature_cols_citywide['categorical'],\n",
    "    current_feature_cols_citywide['numerical'],\n",
    "    current_feature_cols_citywide['time'],\n",
    "    current_feature_cols_citywide['drop']\n",
    ")\n",
    "\n",
    "print(f\"\\nCitywide training set features shape: {X_city.shape}\")\n",
    "print(f\"Citywide training set target shape: {y_city.shape}\")\n",
    "print(f\"Citywide test set features shape: {X_city_test.shape}\")\n",
    "print(f\"Citywide test set target shape: {y_city_test.shape}\")\n",
    "\n",
    "city_best_models = {}\n",
    "city_results = {}\n",
    "\n",
    "pipelines_city, preprocessing_strategies_city = create_model_pipelines(\n",
    "    current_feature_cols_citywide['categorical'],\n",
    "    current_feature_cols_citywide['numerical'],\n",
    "    current_feature_cols_citywide['time'],\n",
    "    X_city\n",
    ")\n",
    "param_grids_city = get_param_grids(preprocessing_strategies_city)\n",
    "\n",
    "print(f\"\\n{'='*50}\\nTraining models for the entire city\\n{'='*50}\")\n",
    "for model_name_item in models_to_train_city:\n",
    "    if model_name_item in pipelines_city:\n",
    "        city_best_models[model_name_item], city_results[model_name_item] = train_evaluate_model(\n",
    "            'citywide-aggregate',  # Using 'citywide' as pseudo cluster_id\n",
    "            False,\n",
    "            model_name_item,\n",
    "            pipelines_city[model_name_item],\n",
    "            param_grids_city[model_name_item],\n",
    "            X_city,\n",
    "            y_city\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Skipping {model_name_item} as it's not defined in pipelines_city\")\n",
    "\n",
    "# Create and display comparison DataFrame for citywide models\n",
    "if city_results:\n",
    "    city_comparison_df = create_comparison_df(city_results)\n",
    "    print(\"\\nModel Comparison Citywide:\")\n",
    "    print(city_comparison_df)\n",
    "\n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='RMSE', y='Model', data=city_comparison_df.sort_values('RMSE', ascending=True))\n",
    "    plt.title('Citywide Model Comparison (RMSE - lower is better)')\n",
    "    plt.savefig('figures/training/citywide_model_aggregate_comparison.png')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Show feature importance for tree-based models\n",
    "    for model_name_item in ['xgboost', 'random_forest', 'decision_tree']:\n",
    "        if model_name_item in city_best_models:\n",
    "            print(f\"\\nFeature Importance for {model_name_item} (Citywide):\")\n",
    "            plot_feature_importance(model_name_item, city_best_models[model_name_item], X_city, 'citywide-aggregate')\n",
    "\n",
    "    # Show coefficients for linear models\n",
    "    for model_name_item in ['linear', 'lasso', 'ridge']:\n",
    "        if model_name_item in city_best_models:\n",
    "            print(f\"\\nCoefficients for {model_name_item} (Citywide):\")\n",
    "            plot_coefficients(model_name_item, city_best_models[model_name_item], 'citywide-aggregate')\n",
    "    \n",
    "    if not city_comparison_df.empty:\n",
    "        best_city_model_name = city_comparison_df['Model'].iloc[0]\n",
    "        best_city_model_rmse_val = city_comparison_df['RMSE'].iloc[0]\n",
    "        print(f\"\\nBest model for the City (based on validation RMSE): {best_city_model_name} with Validation RMSE: {best_city_model_rmse_val:.4f}\")\n",
    "\n",
    "        # Test best model on the citywide test set\n",
    "        y_city_pred_test = city_best_models[best_city_model_name].predict(X_city_test)\n",
    "        city_test_rmse = np.sqrt(mean_squared_error(y_city_test, y_city_pred_test))\n",
    "        r2_city_test = r2_score(y_city_test, y_city_pred_test)\n",
    "        print(f\"Best city model ({best_city_model_name}) on Test Set: RMSE: {city_test_rmse:.4f}, R²: {r2_city_test:.4f}\")\n",
    "\n",
    "        print(f\"\\nVisualizing predictions on test set for {best_city_model_name} (Citywide):\")\n",
    "        # datetime_col_city[0] is train datetime, datetime_col_city[1] is test datetime\n",
    "        visualize_predictions(best_city_model_name, city_best_models[best_city_model_name], X_city_test, y_city_test, datetime_col_city[1], 'citywide-aggregate')\n",
    "    else:\n",
    "        print(\"No models for citywide\")\n",
    "else:\n",
    "    print(\"No results for citywide\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae469c",
   "metadata": {},
   "source": [
    "## 3. Subset Models (May 10-20)\n",
    "\n",
    "### Frequentist Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this obviously only works if the df is not sampled via CONFIG['sample'] = True\n",
    "\n",
    "df_may = df[\n",
    "    (df['timestamp'].dt.month == 5) &\n",
    "    (df['timestamp'].dt.day >= 10) & \n",
    "    (df['timestamp'].dt.day <= 20)\n",
    "].copy()\n",
    "\n",
    "print(f\"Shape of df_may_subset: {df_may.shape}\")\n",
    "df_may.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c10d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest first to detect potential errors early\n",
    "models_to_train_cluster_may = ['random_forest', 'poisson', 'polynomial','linear', 'lasso', 'ridge', 'decision_tree', 'xgboost']\n",
    "\n",
    "unique_clusters = sorted(df_may['cluster'].unique().tolist())\n",
    "print(f\"Found {len(unique_clusters)} clusters: {unique_clusters}\")\n",
    "\n",
    "# # Store cluster results\n",
    "all_cluster_models = {}\n",
    "all_cluster_results = {}\n",
    "all_cluster_comparisons = {}\n",
    "\n",
    "# Train models for each cluster\n",
    "for i, cluster_id in enumerate(unique_clusters):\n",
    "    print(f\"\\n{'='*50}\\nProcessing Cluster {cluster_id}\\n{'='*50}\")\n",
    "    \n",
    "    # Get data for this cluster\n",
    "    X_cluster, y_cluster, X_cluster_test, y_cluster_test, datetime_col = prepare_cluster_data(cluster_id, df_may)\n",
    "    print(f\"Cluster size: {len(X_cluster)} records\")\n",
    "    \n",
    "    # Train models\n",
    "    models, results = train_cluster_models(cluster_id, X_cluster, y_cluster, models_to_train_cluster_may, subset=True)\n",
    "\n",
    "    # Store results\n",
    "    all_cluster_models[cluster_id] = models\n",
    "    all_cluster_results[cluster_id] = results\n",
    "    all_cluster_comparisons[cluster_id] = create_comparison_df(results)\n",
    "            \n",
    "    print(f\"\\nModel Comparison for Cluster {cluster_id}:\")\n",
    "    comparison_cluster = create_comparison_df(results)\n",
    "    print(comparison_cluster)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='RMSE', y='Model', data=comparison_cluster)\n",
    "    plt.title(f'Cluster {cluster_id} - Model Comparison (RMSE - lower is better)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/training/may_subset/cluster_{cluster_id}_model_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show feature importance for tree-based models\n",
    "    for model_name in ['xgboost', 'random_forest', 'decision_tree']:\n",
    "        if model_name in models:\n",
    "            print(f\"\\nFeature Importance for {model_name} in Cluster {cluster_id}:\")\n",
    "            feature_importance = plot_feature_importance(model_name, models[model_name], X_cluster, 'may_subset')\n",
    "\n",
    "    # \"feature importance\" for regression methods\n",
    "    for model_name in ['linear', 'lasso', 'ridge', 'poisson']:\n",
    "        if model_name in models:\n",
    "            print(f\"\\nCoefficients for {model_name} in Cluster {cluster_id}:\")\n",
    "            coefficients = plot_coefficients(model_name, models[model_name], cluster_id)\n",
    "    \n",
    "    # Visualize best model predictions\n",
    "    best_model_name = comparison_cluster['Model'].iloc[0]\n",
    "    print(f\"Best model for Cluster {cluster_id}: {best_model_name} with validation RMSE: {comparison_cluster['RMSE'].iloc[0]:.4f}\")\n",
    "    \n",
    "    # Test best model on test set\n",
    "    y_cluster_pred = models[best_model_name].predict(X_cluster_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_cluster_test, y_cluster_pred))\n",
    "    print(f\"Best model on test set for Cluster {cluster_id}: {best_model_name} with test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    print(f\"\\nVisualizing predictions on test set (5% of data) for {best_model_name} in Cluster {cluster_id}:\")\n",
    "    pred_df = visualize_predictions(best_model_name, models[best_model_name], X_cluster_test, y_cluster_test, datetime_col[1], 'may_subset') # datetime_col[1] are times corresponding to test set\n",
    "\n",
    "    if i == CONFIG['top_n_clusters']-1:\n",
    "        print(f\"Reached top {CONFIG['top_n_clusters']} clusters. Stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of best models across clusters\n",
    "summary_rows = []\n",
    "for cluster_id in all_cluster_comparisons:\n",
    "    best_model = all_cluster_comparisons[cluster_id].iloc[0]\n",
    "    summary_rows.append({\n",
    "        'Cluster': cluster_id,\n",
    "        'Best Model': best_model['Model'],\n",
    "        'RMSE': best_model['RMSE'],\n",
    "    })\n",
    "\n",
    "cluster_summary = pd.DataFrame(summary_rows).sort_values('RMSE')\n",
    "\n",
    "print(\"\\nBest Models by Cluster:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Plot cluster performance comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "cluster_summary_plot = cluster_summary.copy()\n",
    "cluster_summary_plot['Cluster_Model'] = cluster_summary_plot.apply(\n",
    "    lambda x: f\"Cluster {x['Cluster']}: {x['Best Model']}\", axis=1\n",
    ")\n",
    "sns.barplot(x='RMSE', y='Cluster_Model', data=cluster_summary_plot)\n",
    "plt.title('Best Model Performance by Cluster (RMSE - lower is better)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde712",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64dcfc0",
   "metadata": {},
   "source": [
    "### Bayesian Partial Pooling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3d0bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Subset on stations, for manageable sampling time\n",
    "stations_subs = np.random.choice(df[\"station_name\"].unique(), size=100)\n",
    "df_b_sub = df[df[\"station_name\"].isin(stations_subs)]\n",
    "\n",
    "# Subset to May 10 - May 20\n",
    "df_b_sub = df_b_sub[(df_b_sub['month'] == 5) & (df_b_sub['day'] <= 20) & (df_b_sub['day'] >= 10)]\n",
    "\n",
    "bayesian_df_cluster = df_b_sub[\"cluster\"].copy()\n",
    "\n",
    "b_X, b_y = prepare_data(df_b_sub, CONFIG['target_col'], FEATURE_COLS['categorical'], FEATURE_COLS['numerical'], FEATURE_COLS['time'], FEATURE_COLS['drop'], False)\n",
    "b_X[\"cluster\"] = bayesian_df_cluster\n",
    "\n",
    "groups = b_X[\"cluster\"].unique()\n",
    "n_groups = len(groups)\n",
    "group_idx = pd.Categorical(b_X[\"cluster\"], categories=groups).codes\n",
    "\n",
    "b_categorical_cols = FEATURE_COLS['categorical'] + [\"cluster\"] # add cluster here explicitly as we are building a hierarchical model\n",
    "b_numerical_cols = FEATURE_COLS['numerical']\n",
    "b_time_cols = FEATURE_COLS['time']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), b_numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), b_categorical_cols),\n",
    "        ('time', OneHotEncoder(handle_unknown='ignore', sparse_output=False), b_time_cols),\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "b_X = preprocessor.fit_transform(b_X)\n",
    "b_n_feats = len(preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7538bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling = pm.Model()\n",
    "with partial_pooling:\n",
    "    # hyperpriors for group-level intercepts\n",
    "    mu_alpha = pm.Normal('mu_alpha', mu=0, sigma=10)\n",
    "    sigma_alpha = pm.HalfCauchy('sigma_alpha', beta=5)\n",
    "\n",
    "    # hyperpriors for group-level slopes\n",
    "    mu_beta = pm.Normal('mu_beta', mu=0, sigma=10)\n",
    "    sigma_beta = pm.HalfCauchy('sigma_beta', beta=5)\n",
    "\n",
    "    # group-level intercepts\n",
    "    alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_groups)\n",
    "\n",
    "    # group-level slopes\n",
    "    # beta parameter for each feature for each group\n",
    "    beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta, shape=(n_groups, b_n_feats))\n",
    "\n",
    "    # overdispersion parameter for NegBin (alpha > 0)\n",
    "    alpha_nb = pm.HalfCauchy('alpha_nb', beta=5)\n",
    "\n",
    "    # linear predictor\n",
    "    eta = alpha[group_idx] + pm.math.sum(beta[group_idx] * b_X, axis=1)\n",
    "\n",
    "    # inverse link function: mean mu > 0 for the negative binomial\n",
    "    mu = pm.math.exp(eta)\n",
    "\n",
    "    # likelihood\n",
    "    y_obs = pm.NegativeBinomial('y_obs', mu=mu, alpha=alpha_nb, observed=b_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5360b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with partial_pooling:\n",
    "   posterior_sample = pm.sample(draws=100)\n",
    "   # Only the second file is really needed\n",
    "   # But saving this twice is a defense mechanism in case of crashes\n",
    "   with open('checkpoints/bayesian_neg_binomial_.pkl', 'wb') as outp:\n",
    "      pickle.dump(posterior_sample,outp)\n",
    "   az.plot_trace(posterior_sample)\n",
    "   plt.savefig(\"figures/bayesian_trace_plot.png\")\n",
    "   pm.sample_posterior_predictive(posterior_sample, extend_inferencedata=True)\n",
    "   with open('checkpoints/bayesian_neg_binomial_ppc.pkl', 'wb') as outp:\n",
    "      pickle.dump(posterior_sample,outp)\n",
    "   az.plot_ppc(posterior_sample, num_pp_samples=100);\n",
    "   plt.savefig(\"figures/bayesian_ppc.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
